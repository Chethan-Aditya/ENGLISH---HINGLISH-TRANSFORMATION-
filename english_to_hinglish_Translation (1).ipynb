{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e1a4ff05",
      "metadata": {
        "id": "e1a4ff05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6ce598b-dd5f-455c-be69-75d62a889e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers -U -q\n",
        "import torch\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "462b103f",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462b103f",
        "outputId": "b1322651-078c-4587-c745-d3b39a02ed20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "! pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "49b92691",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49b92691",
        "outputId": "047a2ed8-f202-4a37-a25b-f0d84bb93843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers==4.35.0\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4a80f4de",
      "metadata": {
        "id": "4a80f4de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1b0933-56fd-4ba6-881b-e41f3ea14e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ],
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import nltk\n",
        "\n",
        "# Download the part-of-speech tagger data\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Initialize the MarianMT model and tokenizer\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-hi'\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "# Function to check if a word is a noun\n",
        "def is_noun(text):\n",
        "    # Perform part-of-speech tagging on the input text\n",
        "    ans = nltk.pos_tag([text])\n",
        "    val = ans[0][1]\n",
        "\n",
        "    # Check if the tag represents a noun\n",
        "    if val in ('NN', 'NNS', 'NNPS', 'NNP'):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Sample input sentences\n",
        "input_text = [\n",
        "    \"Definitely share your feedback in the comment section.\",\n",
        "    \"So even if it's a big video, I will clearly mention all the products.\",\n",
        "    \"I was waiting for my bag.\"\n",
        "]\n",
        "\n",
        "# Function to translate and preserve nouns in the input text\n",
        "def translate_and_preserve_nouns(input_text):\n",
        "    translated_sentences = []\n",
        "\n",
        "    for text in input_text:\n",
        "        # Tokenize and generate translation for the input sentence\n",
        "        model_inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        generated_tokens = model.generate(**model_inputs)\n",
        "        translation = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
        "\n",
        "        # Split the input sentence into words and identify nouns\n",
        "        words = text.split()\n",
        "        noun_list = [word for word in words if is_noun(word)]\n",
        "\n",
        "        for noun in noun_list:\n",
        "            noun = noun.replace(',', '')\n",
        "            # Tokenize and generate translation for each noun\n",
        "            model_inputs_noun = tokenizer(noun, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "            generated_tokens_noun = model.generate(**model_inputs_noun)\n",
        "            noun_translation = tokenizer.decode(generated_tokens_noun[0], skip_special_tokens=True)\n",
        "\n",
        "            # Replace the translated noun in the overall translation\n",
        "            translation = translation.replace(noun_translation, noun)\n",
        "\n",
        "        translated_sentences.append(translation)\n",
        "\n",
        "    return translated_sentences\n",
        "\n",
        "# Translate and preserve nouns in the input sentences\n",
        "translated_sentences = translate_and_preserve_nouns(input_text)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the translated sentences\n",
        "for sentence in translated_sentences:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFP8FRbO1K6s",
        "outputId": "aa28f390-2591-4ec7-913d-07c1b2bae48d"
      },
      "id": "aFP8FRbO1K6s",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comment खण्ड में अपनी प्रतिक्रिया को निश्‍चित ही share करें ।\n",
            "तो यह एक बड़ा video है, तो भी मैं स्पष्ट रूप से सभी उत्पादों का mention करेंगे।\n",
            "मैं अपने बैग के लिए इंतजार कर रहा था.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}